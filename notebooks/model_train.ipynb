{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72426</th>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>Mildura</td>\n",
       "      <td>14.9</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>WNW</td>\n",
       "      <td>33.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>1013.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33979</th>\n",
       "      <td>2010-04-05</td>\n",
       "      <td>SydneyAirport</td>\n",
       "      <td>15.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>SW</td>\n",
       "      <td>22.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1021.4</td>\n",
       "      <td>1019.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128299</th>\n",
       "      <td>2013-04-09</td>\n",
       "      <td>Walpole</td>\n",
       "      <td>18.2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESE</td>\n",
       "      <td>35.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1018.6</td>\n",
       "      <td>1017.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144147</th>\n",
       "      <td>2013-11-21</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>18.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>41.0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1011.4</td>\n",
       "      <td>1007.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.8</td>\n",
       "      <td>27.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27037</th>\n",
       "      <td>2017-02-16</td>\n",
       "      <td>Penrith</td>\n",
       "      <td>18.1</td>\n",
       "      <td>38.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENE</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date       Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
       "72426  2014-10-24        Mildura     14.9     35.3       0.0          8.0   \n",
       "33979  2010-04-05  SydneyAirport     15.1     20.9       3.4          4.4   \n",
       "128299 2013-04-09        Walpole     18.2     23.7       0.0          NaN   \n",
       "144147 2013-11-21          Uluru     18.3     29.3       1.0          NaN   \n",
       "27037  2017-02-16        Penrith     18.1     38.3       0.0          NaN   \n",
       "\n",
       "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  \\\n",
       "72426        9.1         WNW           33.0          W  ...        60.0   \n",
       "33979        2.5          SW           22.0         SW  ...        79.0   \n",
       "128299       NaN         ESE           35.0        ESE  ...        85.0   \n",
       "144147       NaN           S           41.0          S  ...        84.0   \n",
       "27037        NaN         ENE           39.0        NNE  ...        69.0   \n",
       "\n",
       "        Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  \\\n",
       "72426          19.0       1014.2       1013.1       8.0       6.0     19.5   \n",
       "33979          65.0       1021.4       1019.1       5.0       6.0     18.9   \n",
       "128299         74.0       1018.6       1017.3       NaN       NaN     20.6   \n",
       "144147         37.0       1011.4       1007.5       NaN       NaN     19.8   \n",
       "27037          27.0          NaN          NaN       NaN       NaN     23.2   \n",
       "\n",
       "        Temp3pm  RainToday  RainTomorrow  \n",
       "72426      32.5         No            No  \n",
       "33979      20.5        Yes           Yes  \n",
       "128299     21.1         No            No  \n",
       "144147     27.5         No            No  \n",
       "27037      37.0         No            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the csv Data as Pnadas dataframe\n",
    "df = pd.read_csv(\"data/weatherAUS.csv\")\n",
    "df['Date'] = df['Date'].astype('datetime64[ns]')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape :  (145460, 20)\n",
      "y shape :  (145460,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the X and Y variables\n",
    "x = df.drop(columns=['Date','RainToday', 'RainTomorrow'])\n",
    "y=df['RainToday']\n",
    "print('x shape : ', x.shape)\n",
    "print('y shape : ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group of the Numerical Features and Categorical Feature \n",
    "num_features = x.select_dtypes(exclude=\"O\").columns\n",
    "cat_features = x.select_dtypes(include=\"O\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Numeric Features :  Index(['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n",
      "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
      "       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n",
      "       'Temp9am', 'Temp3pm'],\n",
      "      dtype='object')\n",
      "**************************************************\n",
      "Categorical Features :  Index(['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm'], dtype='object')\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "print('*'*50)\n",
    "print('Numeric Features : ', num_features)\n",
    "print('*'*50)\n",
    "print('Categorical Features : ', cat_features)\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer  # handling missing values\n",
    "from sklearn.preprocessing import StandardScaler  # handling featuer scaling\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder   # ordinal encoding\n",
    "from sklearn.pipeline import Pipeline    # pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in 'Location variable :  ['Albury' 'BadgerysCreek' 'Cobar' 'CoffsHarbour' 'Moree' 'Newcastle'\n",
      " 'NorahHead' 'NorfolkIsland' 'Penrith' 'Richmond' 'Sydney' 'SydneyAirport'\n",
      " 'WaggaWagga' 'Williamtown' 'Wollongong' 'Canberra' 'Tuggeranong'\n",
      " 'MountGinini' 'Ballarat' 'Bendigo' 'Sale' 'MelbourneAirport' 'Melbourne'\n",
      " 'Mildura' 'Nhil' 'Portland' 'Watsonia' 'Dartmoor' 'Brisbane' 'Cairns'\n",
      " 'GoldCoast' 'Townsville' 'Adelaide' 'MountGambier' 'Nuriootpa' 'Woomera'\n",
      " 'Albany' 'Witchcliffe' 'PearceRAAF' 'PerthAirport' 'Perth' 'SalmonGums'\n",
      " 'Walpole' 'Hobart' 'Launceston' 'AliceSprings' 'Darwin' 'Katherine'\n",
      " 'Uluru']\n",
      "======================================================\n",
      "Categories in 'WindGustDir variable :  ['W' 'WNW' 'WSW' 'NE' 'NNW' 'N' 'NNE' 'SW' nan 'ENE' 'SSE' 'S' 'NW' 'SE'\n",
      " 'ESE' 'E' 'SSW']\n",
      "======================================================\n",
      "Categories in 'WindDir9am variable :  ['W' 'NNW' 'SE' 'ENE' 'SW' 'SSE' 'S' 'NE' nan 'SSW' 'N' 'WSW' 'ESE' 'E'\n",
      " 'NW' 'WNW' 'NNE']\n",
      "======================================================\n",
      "Categories in 'WindDir3pm variable :  ['WNW' 'WSW' 'E' 'NW' 'W' 'SSE' 'ESE' 'ENE' 'NNW' 'SSW' 'SW' 'SE' 'N' 'S'\n",
      " 'NNE' nan 'NE']\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "for i in cat_features:\n",
    "    print(f\"Categories in '{i} variable : \", end=\" \")\n",
    "    print(df[i].unique())\n",
    "    print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Pipeline\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('SimpleImputer',SimpleImputer(strategy='median')),\n",
    "        ('StandardScaler',StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Categorical Pipeline\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('SimpleImputer',SimpleImputer(strategy='most_frequent')),\n",
    "        ('oneHot',OneHotEncoder(sparse=False, drop='first', dtype=np.int16))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# combine num_pipeline and cat_pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pipeline',num_pipeline,num_features),\n",
    "    ('categorical_pipeline',cat_pipeline,cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116368, 20), (29092, 20), (116368,), (29092,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36199429, -0.76395034,  1.40548049, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.94823195,  2.29793019, -0.27526853, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.39340494,  0.47773393, -0.25159601, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.72167303, -0.21365845, -0.27526853, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.53320915, -1.1872518 , -0.27526853, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.56616349,  2.45314073, -0.27526853, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(preprocessor.fit_transform(x_train),columns=preprocessor.get_feature_names_out())\n",
    "x_test = pd.DataFrame(preprocessor.transform(x_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "sme = SMOTEENN(random_state=42)\n",
    "x_res, y_res = sme.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Evaluate Model\n",
    "def evaluate_model(true, predicted):\n",
    "    print(\"accuracy_score\")\n",
    "    accuracy_score1 = accuracy_score(true, predicted)\n",
    "    print(\"classification_report\")\n",
    "    classification_report1 = classification_report(true, predicted)\n",
    "    print(\"confusion_matrix\")\n",
    "    confusion_matrix1 = confusion_matrix(true, predicted)\n",
    "    return accuracy_score1, classification_report1, confusion_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\":LogisticRegression(n_jobs=-1),\n",
    "    \"Lasso\":Lasso(),\n",
    "    \"Ridge\":Ridge(),\n",
    "    \"KNeighborsClassifier\":KNeighborsClassifier(n_jobs=-1),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Classifier\":RandomForestClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(n_jobs=-1),\n",
    "    \"CatBoostClassifier\":CatBoostClassifier(verbose=False),\n",
    "    \"SVC\": SVC(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "LogisticRegression\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.8043104633576241\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85     22039\n",
      "           1       0.95      1.00      0.98      6396\n",
      "           2       0.10      0.88      0.18       657\n",
      "\n",
      "    accuracy                           0.80     29092\n",
      "   macro avg       0.68      0.87      0.67     29092\n",
      "weighted avg       0.97      0.80      0.86     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[16444   303  5292]\n",
      " [   20  6376     0]\n",
      " [   78     0   579]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "Lasso\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.21985425546542003\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     22039\n",
      "           1       0.22      1.00      0.36      6396\n",
      "           2       0.00      0.00      0.00       657\n",
      "\n",
      "    accuracy                           0.22     29092\n",
      "   macro avg       0.07      0.33      0.12     29092\n",
      "weighted avg       0.05      0.22      0.08     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[    0 22039     0]\n",
      " [    0  6396     0]\n",
      " [    0   657     0]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "Ridge\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.4264402584903066\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -2.0       0.00      0.00      0.00         0\n",
      "        -1.0       0.00      0.00      0.00         0\n",
      "         0.0       0.94      0.30      0.46     22039\n",
      "         1.0       0.27      0.83      0.41      6396\n",
      "         2.0       0.17      0.60      0.26       657\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43     29092\n",
      "   macro avg       0.23      0.29      0.19     29092\n",
      "weighted avg       0.77      0.43      0.44     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[    0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0]\n",
      " [    1    12  6679 14073  1273     1]\n",
      " [    0     0   419  5336   637     4]\n",
      " [    0     0    14   248   391     4]\n",
      " [    0     0     0     0     0     0]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "KNeighborsClassifier\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.6515193180255741\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.60      0.73     22039\n",
      "           1       0.47      0.83      0.60      6396\n",
      "           2       0.12      0.70      0.20       657\n",
      "\n",
      "    accuracy                           0.65     29092\n",
      "   macro avg       0.51      0.71      0.51     29092\n",
      "weighted avg       0.83      0.65      0.69     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[13174  5886  2979]\n",
      " [  617  5323   456]\n",
      " [   90   110   457]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "DecisionTree\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.9515674412209543\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     22039\n",
      "           1       1.00      1.00      1.00      6396\n",
      "           2       0.27      0.67      0.38       657\n",
      "\n",
      "    accuracy                           0.95     29092\n",
      "   macro avg       0.75      0.87      0.78     29092\n",
      "weighted avg       0.98      0.95      0.96     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[20849     0  1190]\n",
      " [    0  6396     0]\n",
      " [  219     0   438]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "Random Forest Classifier\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.9788945414546955\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     22039\n",
      "           1       1.00      1.00      1.00      6396\n",
      "           2       0.52      0.70      0.60       657\n",
      "\n",
      "    accuracy                           0.98     29092\n",
      "   macro avg       0.84      0.89      0.86     29092\n",
      "weighted avg       0.98      0.98      0.98     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[21622     0   417]\n",
      " [    0  6396     0]\n",
      " [  197     0   460]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "XGBClassifier\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.9756634126220267\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     22039\n",
      "           1       1.00      1.00      1.00      6396\n",
      "           2       0.48      0.75      0.58       657\n",
      "\n",
      "    accuracy                           0.98     29092\n",
      "   macro avg       0.82      0.91      0.86     29092\n",
      "weighted avg       0.98      0.98      0.98     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[21495     2   542]\n",
      " [    1  6395     0]\n",
      " [  163     0   494]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "CatBoostClassifier\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.9740134744947064\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     22039\n",
      "           1       1.00      1.00      1.00      6396\n",
      "           2       0.46      0.75      0.57       657\n",
      "\n",
      "    accuracy                           0.97     29092\n",
      "   macro avg       0.82      0.91      0.85     29092\n",
      "weighted avg       0.98      0.97      0.98     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[21448     0   591]\n",
      " [    2  6394     0]\n",
      " [  163     0   494]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "SVC\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.90915028186443\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94     22039\n",
      "           1       0.91      0.98      0.95      6396\n",
      "           2       0.23      0.79      0.35       657\n",
      "\n",
      "    accuracy                           0.91     29092\n",
      "   macro avg       0.71      0.89      0.74     29092\n",
      "weighted avg       0.95      0.91      0.93     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[19649   609  1781]\n",
      " [  114  6280     2]\n",
      " [  137     0   520]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "AdaBoostClassifier\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.8805857280351986\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.91     22039\n",
      "           1       1.00      1.00      1.00      6396\n",
      "           2       0.14      0.87      0.25       657\n",
      "\n",
      "    accuracy                           0.88     29092\n",
      "   macro avg       0.71      0.91      0.72     29092\n",
      "weighted avg       0.98      0.88      0.92     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[18650     0  3389]\n",
      " [    0  6396     0]\n",
      " [   85     0   572]]\n",
      "**************************************************\n",
      "\n",
      "accuracy_score\n",
      "classification_report\n",
      "confusion_matrix\n",
      "GaussianNB\n",
      "Model Performance for Testing set\n",
      "Model accuarcy : 0.559638388560429\n",
      "==================================================\n",
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.42      0.59     22039\n",
      "           1       0.59      0.99      0.74      6396\n",
      "           2       0.07      0.91      0.13       657\n",
      "\n",
      "    accuracy                           0.56     29092\n",
      "   macro avg       0.55      0.77      0.49     29092\n",
      "weighted avg       0.88      0.56      0.61     29092\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix\n",
      "[[9347 4437 8255]\n",
      " [  60 6336    0]\n",
      " [  47   12  598]]\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "acuracy_score_list = []\n",
    "class_report = []\n",
    "matrics = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(x_res, y_res)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    model_accuracy, model_classification_report, model_confusion_matrix = evaluate_model(y_test, y_pred.round())\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print(\"Model Performance for Testing set\")\n",
    "    print(\"Model accuarcy : {}\".format(model_accuracy))\n",
    "    print(\"=\"*50)\n",
    "    print(\"classification_report :\")\n",
    "    print(model_classification_report)\n",
    "    print(\"=\"*50)\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(model_confusion_matrix)\n",
    "\n",
    "    acuracy_score_list.append(model_accuracy)\n",
    "    class_report.append(model_classification_report)\n",
    "    matrics.append(model_confusion_matrix)\n",
    "    print(\"*\"*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
